#!/usr/bin/env python
# -*- coding: utf-8 -*-
import os
import sys
import argparse
import datetime
import getpass
from contextlib import contextmanager
import pymysql
from pymysqlreplication import BinLogStreamReader
from pymysqlreplication.event import QueryEvent, RotateEvent, FormatDescriptionEvent

from pymysqlreplication.row_event import (
    WriteRowsEvent,
    UpdateRowsEvent,
    DeleteRowsEvent,
)

if sys.version > '3':
    PY3PLUS = True
else:
    PY3PLUS = False


def is_valid_datetime(string):
    try:
        datetime.datetime.strptime(string, "%Y-%m-%d %H:%M:%S")
        return True
    except:
        return False


def create_unique_file(filename):
    version = 0
    result_file = filename
    # if we have to try more than 1000 times, something is seriously wrong
    while os.path.exists(result_file) and version < 1000:
        result_file = filename + '.' + str(version)
        version += 1
    if version >= 1000:
        raise OSError('cannot create unique file %s.[0-1000]' % filename)
    return result_file


@contextmanager
def temp_open(filename, mode):
    f = open(filename, mode)
    try:
        yield f
    finally:
        f.close()
        os.remove(filename)


def parse_args():
    """parse args for binlog2sql"""

    parser = argparse.ArgumentParser(
        description='Parse MySQL binlog to SQL you want', add_help=False)
    connect_setting = parser.add_argument_group('connect setting')
    connect_setting.add_argument(
        '-h',
        '--host',
        dest='host',
        type=str,
        help='Host the MySQL database server located',
        default='127.0.0.1')
    connect_setting.add_argument(
        '-u',
        '--user',
        dest='user',
        type=str,
        help='MySQL Username to log in as',
        default='root')
    connect_setting.add_argument(
        '-p',
        '--password',
        dest='password',
        type=str,
        nargs='*',
        help='MySQL Password to use',
        default='')
    connect_setting.add_argument(
        '-P',
        '--port',
        dest='port',
        type=int,
        help='MySQL port to use',
        default=3306)
    interval = parser.add_argument_group('interval filter')
    interval.add_argument(
        '--start-file',
        dest='start_file',
        type=str,
        help='Start binlog file to be parsed')
    interval.add_argument(
        '--start-position',
        '--start-pos',
        dest='start_pos',
        type=int,
        help='Start position of the --start-file',
        default=4)
    interval.add_argument(
        '--stop-file',
        '--end-file',
        dest='end_file',
        type=str,
        help="Stop binlog file to be parsed. default: '--start-file'",
        default='')
    interval.add_argument(
        '--stop-position',
        '--end-pos',
        dest='end_pos',
        type=int,
        help="Stop position. default: latest position of '--stop-file'",
        default=0)
    interval.add_argument(
        '--start-datetime',
        dest='start_time',
        type=str,
        help="Start time. format %%Y-%%m-%%d %%H:%%M:%%S",
        default='')
    interval.add_argument(
        '--stop-datetime',
        dest='stop_time',
        type=str,
        help="Stop Time. format %%Y-%%m-%%d %%H:%%M:%%S;",
        default='')
    parser.add_argument(
        '--stop-never',
        dest='stop_never',
        action='store_true',
        default=False,
        help=
        "Continuously parse binlog. default: stop at the latest event when you start."
    )
    parser.add_argument(
        '--help',
        dest='help',
        action='store_true',
        help='help information',
        default=False)

    schema = parser.add_argument_group('schema filter')
    schema.add_argument(
        '-d',
        '--databases',
        dest='databases',
        type=str,
        nargs='*',
        help='dbs you want to process',
        default='')
    schema.add_argument(
        '-t',
        '--tables',
        dest='tables',
        type=str,
        nargs='*',
        help='tables you want to process',
        default='')

    event = parser.add_argument_group('type filter')
    event.add_argument(
        '--only-dml',
        dest='only_dml',
        action='store_true',
        default=False,
        help='only print dml, ignore ddl')
    event.add_argument(
        '--sql-type',
        dest='sql_type',
        type=str,
        nargs='*',
        default=['INSERT', 'UPDATE', 'DELETE'],
        help='Sql type you want to process, support INSERT, UPDATE, DELETE.')

    # exclusive = parser.add_mutually_exclusive_group()
    parser.add_argument(
        '-K',
        '--no-primary-key',
        dest='no_pk',
        action='store_true',
        help='Generate insert sql without primary key if exists',
        default=False)
    parser.add_argument(
        '-B',
        '--flashback',
        dest='flashback',
        action='store_true',
        help='Flashback data to start_position of start_file',
        default=False)
    parser.add_argument(
        '--back-interval',
        dest='back_interval',
        type=float,
        default=1.0,
        help=
        "Sleep time between chunks of 1000 rollback sql. set it to 0 if do not need sleep"
    )
    return parser


def command_line_args(args):
    need_print_help = False if args else True
    parser = parse_args()
    args = parser.parse_args(args)
    if args.help or need_print_help:
        parser.print_help()
        sys.exit(1)
    if not args.start_file:
        raise ValueError('Lack of parameter: start_file')
    if args.flashback and args.stop_never:
        raise ValueError('Only one of flashback or stop-never can be True')
    if args.flashback and args.no_pk:
        raise ValueError('Only one of flashback or no_pk can be True')
    if (args.start_time and not is_valid_datetime(args.start_time)) or \
            (args.stop_time and not is_valid_datetime(args.stop_time)):
        raise ValueError('Incorrect datetime argument')
    if not args.password:
        args.password = getpass.getpass()
    else:
        args.password = args.password[0]
    return args


def compare_items(items):
    # caution: if v is NULL, may need to process
    (k, v) = items
    if v is None:
        return '`%s` IS %%s' % k
    else:
        return '`%s`=%%s' % k


def fix_object(value):
    """Fixes python objects so that they can be properly inserted into SQL queries"""
    if isinstance(value, set):
        value = ','.join(value)
    if PY3PLUS and isinstance(value, bytes):
        return value.decode('utf-8')
    elif not PY3PLUS and isinstance(value, unicode):
        return value.encode('utf-8')
    else:
        return value


def is_dml_event(event):
    if isinstance(event, WriteRowsEvent) or isinstance(
            event, UpdateRowsEvent) or isinstance(event, DeleteRowsEvent):
        return True
    else:
        return False


def event_type(event):
    t = None
    if isinstance(event, WriteRowsEvent):
        t = 'INSERT'
    elif isinstance(event, UpdateRowsEvent):
        t = 'UPDATE'
    elif isinstance(event, DeleteRowsEvent):
        t = 'DELETE'
    return t


def concat_sql_from_binlog_event(cursor,
                                 binlog_event,
                                 row=None,
                                 e_start_pos=None,
                                 flashback=False,
                                 no_pk=False):
    if flashback and no_pk:
        raise ValueError('only one of flashback or no_pk can be True')
    if not (isinstance(binlog_event, WriteRowsEvent)
            or isinstance(binlog_event, UpdateRowsEvent)
            or isinstance(binlog_event, DeleteRowsEvent)
            or isinstance(binlog_event, QueryEvent)):
        raise ValueError(
            'binlog_event must be WriteRowsEvent, UpdateRowsEvent, DeleteRowsEvent or QueryEvent'
        )

    sql = ''
    if isinstance(binlog_event, WriteRowsEvent) or isinstance(binlog_event, UpdateRowsEvent) \
            or isinstance(binlog_event, DeleteRowsEvent):
        pattern = generate_sql_pattern(
            binlog_event, row=row, flashback=flashback, no_pk=no_pk)
        sql = cursor.mogrify(pattern['template'], pattern['values'])
        time = datetime.datetime.fromtimestamp(binlog_event.timestamp)
        sql += ' #start %s end %s time %s' % (
            e_start_pos, binlog_event.packet.log_pos, time)
    elif flashback is False and isinstance(binlog_event, QueryEvent) and binlog_event.query != 'BEGIN' \
            and binlog_event.query != 'COMMIT':
        if binlog_event.schema:
            sql = 'USE {0};\n'.format(binlog_event.schema)
        sql += '{0};'.format(fix_object(binlog_event.query))

    return sql


def generate_sql_pattern(binlog_event, row=None, flashback=False, no_pk=False):
    template = ''
    values = []
    if flashback is True:
        if isinstance(binlog_event, WriteRowsEvent):
            template = 'DELETE FROM `{0}`.`{1}` WHERE {2} LIMIT 1;'.format(
                binlog_event.schema, binlog_event.table, ' AND '.join(
                    map(compare_items, row['values'].items())))
            values = map(fix_object, row['values'].values())
        elif isinstance(binlog_event, DeleteRowsEvent):
            template = 'INSERT INTO `{0}`.`{1}`({2}) VALUES ({3});'.format(
                binlog_event.schema, binlog_event.table, ', '.join(
                    map(lambda key: '`%s`' % key, row['values'].keys())),
                ', '.join(['%s'] * len(row['values'])))
            values = map(fix_object, row['values'].values())
        elif isinstance(binlog_event, UpdateRowsEvent):
            template = 'UPDATE `{0}`.`{1}` SET {2} WHERE {3} LIMIT 1;'.format(
                binlog_event.schema, binlog_event.table, ', '.join(
                    ['`%s`=%%s' % x for x in row['before_values'].keys()]),
                ' AND '.join(map(compare_items, row['after_values'].items())))
            values = map(
                fix_object,
                list(row['before_values'].values()) + list(
                    row['after_values'].values()))
    else:
        if isinstance(binlog_event, WriteRowsEvent):
            if no_pk:
                # print binlog_event.__dict__
                # tableInfo = (binlog_event.table_map)[binlog_event.table_id]
                # if tableInfo.primary_key:
                #     row['values'].pop(tableInfo.primary_key)
                if binlog_event.primary_key:
                    row['values'].pop(binlog_event.primary_key)

            template = 'INSERT INTO `{0}`.`{1}`({2}) VALUES ({3});'.format(
                binlog_event.schema, binlog_event.table, ', '.join(
                    map(lambda key: '`%s`' % key, row['values'].keys())),
                ', '.join(['%s'] * len(row['values'])))
            values = map(fix_object, row['values'].values())
        elif isinstance(binlog_event, DeleteRowsEvent):
            template = 'DELETE FROM `{0}`.`{1}` WHERE {2} LIMIT 1;'.format(
                binlog_event.schema, binlog_event.table, ' AND '.join(
                    map(compare_items, row['values'].items())))
            values = map(fix_object, row['values'].values())
        elif isinstance(binlog_event, UpdateRowsEvent):
            template = 'UPDATE `{0}`.`{1}` SET {2} WHERE {3} LIMIT 1;'.format(
                binlog_event.schema, binlog_event.table, ', '.join(
                    ['`%s`=%%s' % k for k in row['after_values'].keys()]),
                ' AND '.join(map(compare_items, row['before_values'].items())))
            values = map(
                fix_object,
                list(row['after_values'].values()) + list(
                    row['before_values'].values()))

    return {'template': template, 'values': list(values)}


def reversed_lines(fin):
    """Generate the lines of file in reverse order."""
    part = ''
    for block in reversed_blocks(fin):
        if PY3PLUS:
            block = block.decode("utf-8")
        for c in reversed(block):
            if c == '\n' and part:
                yield part[::-1]
                part = ''
            part += c
    if part:
        yield part[::-1]


def reversed_blocks(fin, block_size=4096):
    """Generate blocks of file's contents in reverse order."""
    fin.seek(0, os.SEEK_END)
    here = fin.tell()
    while 0 < here:
        delta = min(block_size, here)
        here -= delta
        fin.seek(here, os.SEEK_SET)
        yield fin.read(delta)


class Binlog2sql(object):
    def __init__(self,
                 connection_settings,
                 start_file=None,
                 start_pos=None,
                 end_file=None,
                 end_pos=None,
                 start_time=None,
                 stop_time=None,
                 only_schemas=None,
                 only_tables=None,
                 no_pk=False,
                 flashback=False,
                 stop_never=False,
                 back_interval=1.0,
                 only_dml=True,
                 sql_type=None):
        """
        conn_setting: {'host': 127.0.0.1, 'port': 3306, 'user': user, 'passwd': passwd, 'charset': 'utf8'}
        """

        if not start_file:
            raise ValueError('Lack of parameter: start_file')

        self.conn_setting = connection_settings
        self.start_file = start_file
        self.start_pos = start_pos if start_pos else 4  # use binlog v4
        self.end_file = end_file if end_file else start_file
        self.end_pos = end_pos
        if start_time:
            self.start_time = datetime.datetime.strptime(
                start_time, "%Y-%m-%d %H:%M:%S")
        else:
            self.start_time = datetime.datetime.strptime(
                '1980-01-01 00:00:00', "%Y-%m-%d %H:%M:%S")
        if stop_time:
            self.stop_time = datetime.datetime.strptime(
                stop_time, "%Y-%m-%d %H:%M:%S")
        else:
            self.stop_time = datetime.datetime.strptime(
                '2999-12-31 00:00:00', "%Y-%m-%d %H:%M:%S")

        self.only_schemas = only_schemas if only_schemas else None
        self.only_tables = only_tables if only_tables else None
        self.no_pk, self.flashback, self.stop_never, self.back_interval = (
            no_pk, flashback, stop_never, back_interval)
        self.only_dml = only_dml
        self.sql_type = [t.upper() for t in sql_type] if sql_type else []

        self.binlogList = []
        self.connection = pymysql.connect(**self.conn_setting)
        with self.connection as cursor:
            cursor.execute("SHOW MASTER STATUS")
            self.eof_file, self.eof_pos = cursor.fetchone()[:2]
            cursor.execute("SHOW MASTER LOGS")
            bin_index = [row[0] for row in cursor.fetchall()]
            if self.start_file not in bin_index:
                raise ValueError(
                    'parameter error: start_file %s not in mysql server' %
                    self.start_file)
            binlog2i = lambda x: x.split('.')[1]
            for binary in bin_index:
                if binlog2i(self.start_file) <= binlog2i(binary) <= binlog2i(
                        self.end_file):
                    self.binlogList.append(binary)

            cursor.execute("SELECT @@server_id")
            self.server_id = cursor.fetchone()[0]
            if not self.server_id:
                raise ValueError(
                    'missing server_id in %s:%s' % (self.conn_setting['host'],
                                                    self.conn_setting['port']))

    def process_binlog(self):
        stream = BinLogStreamReader(
            connection_settings=self.conn_setting,
            server_id=self.server_id,
            log_file=self.start_file,
            log_pos=self.start_pos,
            only_schemas=self.only_schemas,
            only_tables=self.only_tables,
            resume_stream=True,
            blocking=True)

        flag_last_event = False
        e_start_pos, last_pos = stream.log_pos, stream.log_pos
        # to simplify code, we do not use flock for tmp_file.
        tmp_file = create_unique_file(
            '%s.%s' % (self.conn_setting['host'], self.conn_setting['port']))
        with temp_open(tmp_file, "w") as f_tmp, self.connection as cursor:
            for binlog_event in stream:
                if not self.stop_never:
                    try:
                        event_time = datetime.datetime.fromtimestamp(
                            binlog_event.timestamp)
                    except OSError:
                        event_time = datetime.datetime(1980, 1, 1, 0, 0)
                    if (stream.log_file == self.end_file and stream.log_pos == self.end_pos) or \
                            (stream.log_file == self.eof_file and stream.log_pos == self.eof_pos):
                        flag_last_event = True
                    elif event_time < self.start_time:
                        if not (isinstance(binlog_event, RotateEvent)
                                or isinstance(binlog_event,
                                              FormatDescriptionEvent)):
                            last_pos = binlog_event.packet.log_pos
                        continue
                    elif (stream.log_file not in self.binlogList) or \
                            (self.end_pos and stream.log_file == self.end_file and stream.log_pos > self.end_pos) or \
                            (stream.log_file == self.eof_file and stream.log_pos > self.eof_pos) or \
                            (event_time >= self.stop_time):
                        break
                    # else:
                    #     raise ValueError('unknown binlog file or position')

                if isinstance(binlog_event,
                              QueryEvent) and binlog_event.query == 'BEGIN':
                    e_start_pos = last_pos

                if isinstance(binlog_event, QueryEvent) and not self.only_dml:
                    sql = concat_sql_from_binlog_event(
                        cursor=cursor,
                        binlog_event=binlog_event,
                        flashback=self.flashback,
                        no_pk=self.no_pk)
                    if sql:
                        print(sql)
                elif is_dml_event(binlog_event) and event_type(
                        binlog_event) in self.sql_type:
                    for row in binlog_event.rows:
                        sql = concat_sql_from_binlog_event(
                            cursor=cursor,
                            binlog_event=binlog_event,
                            no_pk=self.no_pk,
                            row=row,
                            flashback=self.flashback,
                            e_start_pos=e_start_pos)
                        if self.flashback:
                            f_tmp.write(sql + '\n')
                        else:
                            print(sql)

                if not (isinstance(binlog_event, RotateEvent)
                        or isinstance(binlog_event, FormatDescriptionEvent)):
                    last_pos = binlog_event.packet.log_pos
                if flag_last_event:
                    break

            stream.close()
            f_tmp.close()
            if self.flashback:
                self.print_rollback_sql(filename=tmp_file)
        return True

    def print_rollback_sql(self, filename):
        """print rollback sql from tmp_file"""
        with open(filename, "rb") as f_tmp:
            batch_size = 1000
            i = 0
            for line in reversed_lines(f_tmp):
                print(line.rstrip())
                if i >= batch_size:
                    i = 0
                    if self.back_interval:
                        print('SELECT SLEEP(%s);' % self.back_interval)
                else:
                    i += 1

    def __del__(self):
        pass


if __name__ == '__main__':
    args = command_line_args(sys.argv[1:])
    conn_setting = {
        'host': args.host,
        'port': args.port,
        'user': args.user,
        'passwd': args.password,
        'charset': 'utf8'
    }
    binlog2sql = Binlog2sql(
        connection_settings=conn_setting,
        start_file=args.start_file,
        start_pos=args.start_pos,
        end_file=args.end_file,
        end_pos=args.end_pos,
        start_time=args.start_time,
        stop_time=args.stop_time,
        only_schemas=args.databases,
        only_tables=args.tables,
        no_pk=args.no_pk,
        flashback=args.flashback,
        stop_never=args.stop_never,
        back_interval=args.back_interval,
        only_dml=args.only_dml,
        sql_type=args.sql_type)
    binlog2sql.process_binlog()
