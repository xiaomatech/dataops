<?xml version="1.0" encoding="UTF-8"?>
<!--
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
<configuration supports_final="true">
    <property>
        <name>spark.yarn.queue</name>
        <value>default</value>
        <description>
            The name of the YARN queue to which the application is submitted.
        </description>
        <depends-on>
            <property>
                <type>capacity-scheduler</type>
                <name>yarn.scheduler.capacity.root.queues</name>
            </property>
        </depends-on>
        <on-ambari-upgrade add="false"/>
    </property>

    <property>
        <name>spark.driver.extraClassPath</name>
        <value>{{ extra_class_path }}</value>
        <description>
            Set a special class path to use when launching the driver JVM.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.executor.extraClassPath</name>
        <value>{{ extra_class_path }}</value>
        <description>
            Set a special class path to use when launching the executor JVM.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>

    <property>
        <name>spark.driver.extraLibraryPath</name>
        <value>{{ spark_hadoop_lib_native }}</value>
        <description>
            Set a special library path to use when launching the driver JVM.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.executor.extraLibraryPath</name>
        <value>{{ spark_hadoop_lib_native }}</value>
        <description>
            Set a special library path to use when launching the executor JVM.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.history.provider</name>
        <value>org.apache.spark.deploy.history.FsHistoryProvider</value>
        <description>
            Name of history provider
        </description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.history.ui.port</name>
        <value>18081</value>
        <description>
            The port to which the web interface of the History Server binds.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.history.fs.logDirectory</name>
        <display-name>Spark History FS Log directory</display-name>
        <value>hdfs:///logs/spark/</value>
        <description>
            Base directory for history spark application log.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.history.kerberos.principal</name>
        <value>none</value>
        <description>
            Kerberos principal name for the Spark History Server.
        </description>
        <property-type>KERBEROS_PRINCIPAL</property-type>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.history.kerberos.keytab</name>
        <value>none</value>
        <description>
            Location of the kerberos keytab file for the Spark History Server.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.eventLog.enabled</name>
        <value>true</value>
        <description>
            Whether to log Spark events, useful for reconstructing the Web UI after the application has finished.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.eventLog.dir</name>
        <display-name>Spark Eventlog directory</display-name>
        <value>hdfs:///logs/spark/</value>
        <description>
            Base directory in which Spark events are logged, if spark.eventLog.enabled is true.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.eventLog.rolling.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>spark.eventLog.allowErasureCoding</name>
        <value>true</value>
    </property>
    <property>
        <name>spark.eventLog.compress</name>
        <value>true</value>
        <description>
            Whether to compress
        </description>
        <on-ambari-upgrade add="true"/>
    </property>

    <property>
        <name>spark.yarn.historyServer.address</name>
        <value>{{ spark_history_server_host }}:{{ spark_history_ui_port }}</value>
        <description>The address of the Spark history server (i.e. host.com:18081). The address should not contain a
            scheme (http://). Defaults to not being set since the history server is an optional service. This address is
            given to the YARN ResourceManager when the Spark application finishes to link the application from the
            ResourceManager UI to the Spark history server UI.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>


    <property>
        <name>spark.history.fs.cleaner.enabled</name>
        <value>true</value>
        <description>Specifies whether the History Server should periodically clean up event logs from storage.
        </description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.history.fs.cleaner.interval</name>
        <value>7d</value>
        <description>How often the filesystem job history cleaner checks for files to delete. Files are only deleted if
            they are older than spark.history.fs.cleaner.maxAge
        </description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.history.fs.cleaner.maxAge</name>
        <value>90d</value>
        <description>Job history files older than this will be deleted when the filesystem history cleaner runs.
        </description>
        <on-ambari-upgrade add="false"/>
    </property>


    <property>
        <name>spark.sql.statistics.fallBackToHdfs</name>
        <value>true</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.sql.autoBroadcastJoinThreshold</name>
        <value>26214400</value>
        <description>Configures the maximum size in bytes for a table that will be broadcast to all worker nodes when
            performing a join.
        </description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.io.compression.lz4.blockSize</name>
        <value>512kb</value>
        <description>Block size in bytes used in LZ4 compression, in the case when LZ4 compression codec is used.
            Lowering this block size will also lower shuffle memory usage when LZ4 is used.
        </description>
        <on-ambari-upgrade add="false"/>
    </property>

    <property>
        <name>spark.yarn.maxAppAttempts</name>
        <value>2</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.executor.instances</name>
        <value>10</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.executor.memory</name>
        <value>20g</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.executor.cores</name>
        <value>4</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.executor.memoryOverhead</name>
        <value>2g</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.yarn.am.memory</name>
        <value>6g</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.yarn.am.cores</name>
        <value>1</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.driver.memory</name>
        <value>10g</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.driver.maxResultSize</name>
        <value>10g</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>

    <property>
        <name>spark.kryoserializer.buffer.max</name>
        <value>1g</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.ui.killEnabled</name>
        <value>false</value>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.port.maxRetries</name>
        <value>500</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.speculation</name>
        <value>true</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.speculation.multiplier</name>
        <value>2.0</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.speculation.quantile</name>
        <value>0.90</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.blacklist.enabled</name>
        <value>true</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>

    <property>
        <name>spark.sql.orc.impl</name>
        <value>native</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.sql.orc.filterPushdown</name>
        <value>true</value>
        <description>Enables filter pushdown for ORC formats.</description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.sql.hive.convertMetastoreOrc</name>
        <value>true</value>
        <description>Enables new ORC format to read/write Hive Tables.</description>
        <on-ambari-upgrade add="false"/>
    </property>

    <property>
        <name>spark.sql.shuffle.partitions</name>
        <value>32</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.sql.streaming.metricsEnabled</name>
        <value>true</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.sql.hive.manageFilesourcePartitions</name>
        <value>true</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>


    <property>
        <name>spark.shuffle.io.serverThreads</name>
        <value>128</value>
        <description>Number of threads used in the server thread pool.</description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.shuffle.io.backLog</name>
        <value>8192</value>
        <description>Requested maximum length of the queue of incoming connections.</description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.shuffle.file.buffer</name>
        <value>1m</value>
        <description>Size of the in-memory buffer for each shuffle file output stream, in KiB unless otherwise
            specified. These buffers reduce the number of disk seeks and system calls made in creating intermediate
            shuffle files.
        </description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.shuffle.unsafe.file.output.buffer</name>
        <value>5m</value>
        <description>The file system for this buffer size after each partition is written in unsafe shuffle writer. In
            KiB unless otherwise specified.
        </description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.unsafe.sorter.spill.reader.buffer.size</name>
        <value>1m</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.master</name>
        <value>yarn</value>
        <description>The deploying mode of spark application.</description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.executor.extraJavaOptions</name>
        <value>-XX:+UseNUMA -XX:ParallelGCThreads=20 -XX:+UseParallelGC
            -Dcarbon.properties.filepath=/etc/spark/carbon.properties
        </value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>
    <property>
        <name>spark.sql.warehouse.dir</name>
        <value>/warehouse</value>
        <description></description>
        <on-ambari-upgrade add="false"/>
    </property>

    <property>
        <name>spark.streaming.backpressure.enabled</name>
        <value>true</value>
        <description>
            Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark
            Streaming to control the receiving rate based on the current batch scheduling delays and processing times so
            that the system receives only as fast as the system can process. Internally, this dynamically sets the
            maximum receiving rate of receivers. This rate is upper bounded by the values
            spark.streaming.receiver.maxRate and spark.streaming.kafka.maxRatePerPartition if they are set
        </description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.streaming.backpressure.initialRate</name>
        <value>10000</value>
        <description>
            This is the initial maximum receiving rate at which each receiver will receive data for the first batch when
            the backpressure mechanism is enabled.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.streaming.receiver.maxRate</name>
        <value>30000</value>
        <description>
            Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each
            stream will consume at most this number of records per second. Setting this configuration to 0 or a negative
            number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for
            mode details.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.streaming.kafka.maxRatePerPartition</name>
        <value>30000</value>
        <description>
            Maximum rate (number of records per second) at which data will be read from each Kafka partition when using
            the new Kafka direct stream API. See the Kafka Integration guide for more details.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.streaming.stopGracefullyOnShutdown</name>
        <value>true</value>
        <description>
            If true, Spark shuts down the StreamingContext gracefully on JVM shutdown rather than immediately.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.serializer</name>
        <value>org.apache.spark.serializer.KryoSerializer</value>
        <description>
            Class to use for serializing objects that will be sent over the network or need to be cached in serialized
            form. The default of Java serialization works with any Serializable Java object but is quite slow, so we
            recommend using org.apache.spark.serializer.KryoSerializer and configuring Kryo serialization when speed is
            necessary. Can be any subclass of org.apache.spark.Serializer.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>


    <property>
        <name>spark.yarn.archive</name>
        <value>hdfs:///apps/spark/spark-yarn-archive.tar.gz</value>
        <description>
            spark yarn archive
        </description>
        <on-ambari-upgrade add="true"/>
    </property>

    <property>
        <name>spark.shuffle.service.enabled</name>
        <value>true</value>
        <description>
            Enables the external shuffle service.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.shuffle.registration.timeout</name>
        <value>2m</value>
        <description>
            spark shuffle registration timeout
        </description>
        <on-ambari-upgrade add="true"/>
    </property>

    <property>
        <name>spark.dynamicAllocation.enabled</name>
        <value>true</value>
        <description>
            Whether to use dynamic resource allocation, which scales the number of executors registered with this
            application up and down based on the workload.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.dynamicAllocation.initialExecutors</name>
        <value>1</value>
        <description>
            Initial number of executors to run if dynamic allocation is enabled.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.dynamicAllocation.maxExecutors</name>
        <value>2000</value>
        <description>
            Upper bound for the number of executors if dynamic allocation is enabled.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.dynamicAllocation.minExecutors</name>
        <value>1</value>
        <description>
            Lower bound for the number of executors if dynamic allocation is enabled.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>

    <property>
        <name>spark.metrics.conf</name>
        <value>/etc/spark/metrics.properties</value>
        <on-ambari-upgrade add="true"/>
    </property>

    <property>
        <name>spark.driver.extraJavaOptions</name>
        <value>-XX:+UseG1GC -Dcarbon.properties.filepath=/etc/spark/carbon.properties</value>
        <description>
            A string of extra JVM options to pass to the driver. For instance, GC settings or other logging.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>

    <property>
        <name>spark.yarn.dist.files</name>
        <value>/etc/spark/carbon.properties</value>
        <description>
            Comma-separated list of files to be placed in the working directory of each executor.
        </description>
        <on-ambari-upgrade add="true"/>
    </property>

    <property>
        <name>spark.sql.cbo</name>
        <value>true</value>
        <value-attributes>
            <type>boolean</type>
        </value-attributes>
        <on-ambari-upgrade add="true"/>
    </property>


    <property>
        <name>spark.dynamicAllocation.executorIdleTimeout</name>
        <value>2m</value>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.stage.maxConsecutiveAttempts</name>
        <value>10</value>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.rpc.io.serverTreads</name>
        <value>64</value>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.memory.offHeap.enable</name>
        <value>true</value>
        <value-attributes>
            <type>boolean</type>
        </value-attributes>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.memory.ofHeap.size</name>
        <value>3g</value>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.shuffle.unsafe.file.ouput.buffer</name>
        <value>5m</value>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.file.transferTo</name>
        <value>false</value>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.shuffle.service.index.cache.size</name>
        <value>8192</value>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.shuffle.registration.maxAttempst</name>
        <value>5</value>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>spark.history.store.path</name>
        <value>/var/log/spark</value>
    </property>

    <property>
        <name>spark.sql.adaptive.enabled</name>
        <value>true</value>
        <value-attributes>
            <type>boolean</type>
        </value-attributes>
        <on-ambari-upgrade add="true"/>
    </property>

    <property>
        <name>spark.sql.adaptive.skewedJoin.enabled</name>
        <value>true</value>
        <value-attributes>
            <type>boolean</type>
        </value-attributes>
        <on-ambari-upgrade add="true"/>
    </property>

    <property>
        <name>spark.shuffle.statistics.verbose</name>
        <value>true</value>
        <value-attributes>
            <type>boolean</type>
        </value-attributes>
        <on-ambari-upgrade add="true"/>
    </property>

    <property>
        <name>spark.sql.adaptive.join.enabled</name>
        <value>true</value>
        <value-attributes>
            <type>boolean</type>
        </value-attributes>
        <on-ambari-upgrade add="true"/>
    </property>

    <property>
        <name>spark.sql.adaptive.allowAdditionalShuffle</name>
        <value>true</value>
        <value-attributes>
            <type>boolean</type>
        </value-attributes>
        <on-ambari-upgrade add="true"/>
    </property>

    <property>
        <name>spark.sql.adaptive.maxNumPostShufflePartitions</name>
        <value>10000</value>
    </property>

    <property>
        <name>spark.sql.adaptive.shuffle.targetPostShuffleInputSize</name>
        <value>100MB</value>
    </property>

    <property>
        <name>spark.submit.deployMode</name>
        <value>cluster</value>
    </property>

    <property>
        <name>spark.sql.parquet.compression.codec</name>
        <value>snappy</value>
    </property>

    <property>
        <name>spark.hadoop.yarn.timeline-service.enabled</name>
        <value>false</value>
    </property>

    <property>
        <name>spark.sql.orc.filterPushdown</name>
        <value>true</value>
    </property>
    <property>
        <name>spark.sql.orc.enabled</name>
        <value>true</value>
    </property>


</configuration>
